#this is required by the vectorizer
def my_tokenizer(x):
    return x.split(' ')